{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import sklearn.cluster \n",
    "import plotly.express as px\n",
    "import community\n",
    "\n",
    "import msg_passing\n",
    "import utils\n",
    "import run\n",
    "import display\n",
    "import parse_data\n",
    "import baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(fdir, f_prefix):\n",
    "    g = msg_passing.load_graph_graphml(fdir + f_prefix + \".graphml\")\n",
    "    hist, diagnostic_hist = msg_passing.load_history(fdir + f_prefix + \".pkl\")\n",
    "    return g, hist, diagnostic_hist\n",
    "\n",
    "def view_history(fdir, f_prefix):\n",
    "    hist, _ = msg_passing.load_history(fdir + f_prefix + \".pkl\") \n",
    "    return hist.keys()\n",
    "\n",
    "def plot_run(fdir, f_prefix, target):\n",
    "    print(\"Plotting run for\", fdir + f_prefix)\n",
    "    g = msg_passing.load_graph_graphml(fdir + f_prefix + \".graphml\")\n",
    "    hist, diagnostic_hist = msg_passing.load_history(fdir + f_prefix + \".pkl\")\n",
    "    display.plot_diagnostic(diagnostic_hist)\n",
    "    display.plot_history(hist, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [47], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m g, hist, diagnostic_hist \u001b[39m=\u001b[39m load_results(outdir, net \u001b[39m+\u001b[39m out_suffix)\n\u001b[0;32m     52\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 53\u001b[0m \u001b[39mwhile\u001b[39;00m(\u001b[39mnot\u001b[39;00m msg_passing\u001b[39m.\u001b[39;49mpermute_edges(g)):\n\u001b[0;32m     54\u001b[0m     count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     55\u001b[0m \u001b[39mprint\u001b[39m(count)\n",
      "File \u001b[1;32mc:\\Users\\gd215\\files\\UCLA\\Research\\Message-Passing\\msg_passing.py:124\u001b[0m, in \u001b[0;36mpermute_edges\u001b[1;34m(g)\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m(i \u001b[39m<\u001b[39m j):\n\u001b[0;32m    123\u001b[0m             permuted[i][j] \u001b[39m=\u001b[39m permuted[j][i]\n\u001b[1;32m--> 124\u001b[0m permuted_g \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39;49mfrom_numpy_matrix(permuted, create_using\u001b[39m=\u001b[39;49mnx\u001b[39m.\u001b[39;49mMultiGraph) \n\u001b[0;32m    125\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mprint\u001b[39m(nx\u001b[39m.\u001b[39mis_connected(permuted_g))\n\u001b[0;32m    126\u001b[0m node_labels \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\gd215\\files\\UCLA\\Research\\Message-Passing\\venv39\\lib\\site-packages\\networkx\\convert_matrix.py:694\u001b[0m, in \u001b[0;36mfrom_numpy_matrix\u001b[1;34m(A, parallel_edges, create_using)\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[39m\"\"\"Returns a graph from numpy matrix.\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \n\u001b[0;32m    605\u001b[0m \u001b[39mThe numpy matrix is interpreted as an adjacency matrix for the graph.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    685\u001b[0m \n\u001b[0;32m    686\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    687\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    688\u001b[0m     (\n\u001b[0;32m    689\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfrom_numpy_matrix is deprecated and will be removed in NetworkX 3.0.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m    693\u001b[0m )\n\u001b[1;32m--> 694\u001b[0m \u001b[39mreturn\u001b[39;00m from_numpy_array(A, parallel_edges\u001b[39m=\u001b[39;49mparallel_edges, create_using\u001b[39m=\u001b[39;49mcreate_using)\n",
      "File \u001b[1;32mc:\\Users\\gd215\\files\\UCLA\\Research\\Message-Passing\\venv39\\lib\\site-packages\\networkx\\convert_matrix.py:1623\u001b[0m, in \u001b[0;36mfrom_numpy_array\u001b[1;34m(A, parallel_edges, create_using)\u001b[0m\n\u001b[0;32m   1620\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown numpy data type: \u001b[39m\u001b[39m{\u001b[39;00mdt\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   1622\u001b[0m \u001b[39m# Make sure we get even the isolated nodes of the graph.\u001b[39;00m\n\u001b[1;32m-> 1623\u001b[0m G\u001b[39m.\u001b[39;49madd_nodes_from(\u001b[39mrange\u001b[39;49m(n))\n\u001b[0;32m   1624\u001b[0m \u001b[39m# Get a list of all the entries in the array with nonzero entries. These\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m \u001b[39m# coordinates become edges in the graph. (convert to int from np.int64)\u001b[39;00m\n\u001b[0;32m   1626\u001b[0m edges \u001b[39m=\u001b[39m ((\u001b[39mint\u001b[39m(e[\u001b[39m0\u001b[39m]), \u001b[39mint\u001b[39m(e[\u001b[39m1\u001b[39m])) \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mA\u001b[39m.\u001b[39mnonzero()))\n",
      "File \u001b[1;32mc:\\Users\\gd215\\files\\UCLA\\Research\\Message-Passing\\venv39\\lib\\site-packages\\networkx\\classes\\graph.py:623\u001b[0m, in \u001b[0;36mGraph.add_nodes_from\u001b[1;34m(self, nodes_for_adding, **attr)\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    622\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNone cannot be a node\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 623\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_adj[n] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madjlist_inner_dict_factory()\n\u001b[0;32m    624\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_node[n] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_attr_dict_factory()\n\u001b[0;32m    625\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_node[n]\u001b[39m.\u001b[39mupdate(newdict)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "infiles = [\n",
    "    \"global_warming_network\",\n",
    "    \"gun_regulations_network\",\n",
    "    \"immigration_network\",\n",
    "    \"inflation_network\",\n",
    "    \"roe_v_wade_network\",\n",
    "    \"trump_impeachment_network\",\n",
    "    \"ukraine_war_network\",\n",
    "    \"vaccine_hesitancy_network\",\n",
    "    \"combined\"\n",
    "]\n",
    "\n",
    "infiles = [\n",
    "    \"global_warming\",\n",
    "    \"gun_regulations\",\n",
    "    \"immigration\",\n",
    "    \"recession_fears\",\n",
    "    \"roe_v_wade\",\n",
    "    \"ukraine_war\",\n",
    "    \"vaccine_hesitancy\",\n",
    "]\n",
    "\n",
    "network_names = [ \n",
    "    \"global warming\",\n",
    "    \"gun regulations\",\n",
    "    \"immigration\",\n",
    "    \"recession fears\",\n",
    "    \"roe v. wade\",\n",
    "    \"ukraine war\",\n",
    "    \"vaccine hesitancy\",\n",
    "]\n",
    "\n",
    "indir = \"input/Networks/\"\n",
    "\n",
    "#outdir = \"output/Incremental_Datasets_2/\"\n",
    "#outdir = \"output/archive/\"\n",
    "outdir = \"output/Networks_v1/\"\n",
    "outdir = \"output/random_edges/\"\n",
    "outdir = \"output/with_windows/\"\n",
    "\n",
    "in_suffix = \"_network.csv\"\n",
    "\n",
    "#out_suffix = \"_random_walks_lr_10-3_30K_dc_095_pl_10_bs_10\"\n",
    "#out_suffix = \"_v3_random_walk_batch_10_path_10_50K_lr_3_dim_3\"\n",
    "out_suffix = \"_network_random_walks_lr_10-3_20K_dc_095_pl_{path_length}_bs_10\"\n",
    "out_suffix = \"_network_random_edge_baseline_random_walks_lr_10-3_20K_dc_095_pl_10_bs_10\" \n",
    "out_suffix = \"_network_random_walks_lr_10-3_20K_dc_095_pl_10_bs_10\"\n",
    "\n",
    "net = infiles[5] \n",
    "g, hist, diagnostic_hist = load_results(outdir, net + out_suffix)\n",
    "\n",
    "count = 0\n",
    "while(not msg_passing.permute_edges(g)):\n",
    "    count += 1\n",
    "print(count)\n",
    "\n",
    "#print(hist.keys())\n",
    "#display.plot_history_with_reference(hist, \"anthony fauci\")\n",
    "#display.plot_top_n_cluster_evaluations(g, [20, 50, 100], 2, 10)\n",
    "#print(view_history(outdir, net + out_suffix))\n",
    "#plot_run(outdir, net + out_suffix, \"biden\")\n",
    "#_ = display.plot_edge_weight_histogram(g, log_scale=False)\n",
    "#_ = display.plot_degree_histogram(g, log_scale=True)\n",
    "\n",
    "#fig = display.plot_confusion_matrix(g, utils.get_top_n_nodes(g, 20), 2, title=net)\n",
    "#_ = display.plot_cos_dist_histogram(g, title=net)\n",
    "#fig.write_html(\"images/vaccine_heatmap.html\")\n",
    "\n",
    "\"\"\"\n",
    "hist_files = []\n",
    "graph_files = []\n",
    "for n in infiles:\n",
    "    h = outdir + n + out_suffix + \".pkl\"\n",
    "    g = outdir + n + out_suffix + \".graphml\"\n",
    "    hist_files.append(h)\n",
    "    graph_files.append(g)\n",
    "#_ = display.plot_diagnostic_grid(hist_files, graph_files, infiles, \"Update Magnitude and Loss\", 4, 2)\n",
    "fig = display.plot_diagnostic_multiple_issues(hist_files, graph_files, network_names, show=True)\n",
    "fig.write_image(\"convergence_plots.pdf\", height=450, width=986)\n",
    "\"\"\"\n",
    "\"\"\" \n",
    "write_dir = \"images/networks_cluster_hdbscan/\"\n",
    "#write_dir = \"output/cyto_pruned_networks/\"\n",
    "for n in infiles:\n",
    "    print(n)\n",
    "    fname = outdir + n + out_suffix + \".graphml\"\n",
    "    #fname = indir + n + in_suffix\n",
    "    #g = msg_passing.load_graph_csv(fname, clean_data=True)\n",
    "    #msg_passing.save_graph(g, write_dir + n + \"_full.graphml\")\n",
    "    g = msg_passing.load_graph_graphml(fname)\n",
    "    pg, _ = msg_passing.prune_graph(g)\n",
    "    #print(parse_data.compute_network_stats(g, include_diameter=False))\n",
    "    top_nodes = 50#len(pg.nodes())\n",
    "    fig = display.plot_confusion_matrix(pg, utils.get_top_n_nodes(pg, top_nodes), 2, title=n, show=False)\n",
    "    fig.write_html(write_dir + n + \"_50_-1s.html\")\n",
    "    #msg_passing.save_graph(pg, write_dir + n + \"_count.graphml\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shortest_path_network(g, nodes1, nodes2):\n",
    "    subgraph_nodes = set()\n",
    "    for n1 in nodes1:\n",
    "        for n2 in nodes2:\n",
    "            sps = list(nx.all_shortest_paths(g, n1, n2))\n",
    "            for sp in sps:\n",
    "                for n in sp:\n",
    "                    subgraph_nodes.add(n) \n",
    "    \n",
    "    return g.subgraph(subgraph_nodes)\n",
    "\n",
    "gf = \"output/Networks_v1/gun_regulations_network_random_walks_lr_10-3_20K_dc_095_pl_{path_length}_bs_10.graphml\"\n",
    "#gf = \"output/Networks_v1/roe_v_wade_network_random_walks_lr_10-3_20K_dc_095_pl_{path_length}_bs_10.graphml\"\n",
    "gf = \"output/Networks_v1/recession_fears_network_random_walks_lr_10-3_20K_dc_095_pl_{path_length}_bs_10.graphml\"\n",
    "g = msg_passing.load_graph_graphml(gf)\n",
    "pg, _ = msg_passing.prune_graph(g) \n",
    "n1 = [\"second amendment\", \"bruen\", \"greg abbott\", \"gerald smith\", \"iowa firearms coalition\", \"supreme court\"]\n",
    "#n2 = [\"second amendment foundation\", \"adam kraut\"]\n",
    "n2 = [\"joe biden\", \"kamala harris\", \"a ban on assault weapons\", \"biden\", \"white house\"]\n",
    "#n1 = [\"donald trump\", \"white house\", \"supreme court\", \"clarence thomas\"]\n",
    "#n2 = [\"republican\", \"republicans\", \"gop\", \"arizona\", \"planned parenthood\", \"anti-abortion\"]\n",
    "n1 = [\"opec\", \"fox news\", \"saudis\"]\n",
    "n2 = [\"jerome powell\", \"joe biden\", \"janet yellen\"]\n",
    "\n",
    "sg = get_shortest_path_network(pg, n1, n2)\n",
    "write_dir = \"output/cyto_pruned_networks/\"\n",
    "outname = write_dir + \"recession_1.graphml\" \n",
    "msg_passing.save_graph(sg, outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1037419582.py, line 41)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [21], line 41\u001b[1;36m\u001b[0m\n\u001b[1;33m    def generate\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "infiles = [\n",
    "    \"global_warming_network\",\n",
    "    \"gun_regulations_network\",\n",
    "    \"immigration_network\",\n",
    "    \"inflation_network\",\n",
    "    \"roe_v_wade_network\",\n",
    "    \"trump_impeachment_network\",\n",
    "    \"ukraine_war_network\",\n",
    "    \"vaccine_hesitancy_network\",\n",
    "    \"combined\"\n",
    "]\n",
    "\n",
    "infiles = [\n",
    "    \"gun_regulations\",\n",
    "    \"immigration\",\n",
    "    \"recession_fears\",\n",
    "    \"roe_v_wade\",\n",
    "    \"ukraine_war\",\n",
    "    \"vaccine_hesitancy\",\n",
    "]\n",
    "\n",
    "indir = \"input/Networks/\"\n",
    "\n",
    "#outdir = \"output/Incremental_Datasets_2/\"\n",
    "#outdir = \"output/archive/\"\n",
    "outdir = \"output/Networks_v1/\"\n",
    "outdir = \"output/random_edges/\"\n",
    "outdir = \"output/with_windows/\"\n",
    "\n",
    "in_suffix = \"_network.csv\"\n",
    "\n",
    "#out_suffix = \"_random_walks_lr_10-3_30K_dc_095_pl_10_bs_10\"\n",
    "#out_suffix = \"_v3_random_walk_batch_10_path_10_50K_lr_3_dim_3\"\n",
    "out_suffix = \"_network_random_walks_lr_10-3_20K_dc_095_pl_{path_length}_bs_10\"\n",
    "out_suffix = \"_network_random_edge_baseline_random_walks_lr_10-3_20K_dc_095_pl_10_bs_10\" \n",
    "out_suffix = \"_network_random_walks_lr_10-3_20K_dc_095_pl_10_bs_10\"\n",
    "\n",
    "net = infiles[5] \n",
    "g, hist, diagnostic_hist = load_results(outdir, net + out_suffix)\n",
    "\n",
    "def generate\n",
    "\n",
    "fig = display.plot_diagnostic_grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDBSCAN clustering results for gun_regulations - num clusters: 13, score: -0.040456127676587926\n",
      "HDBSCAN clustering results for immigration - num clusters: 10, score: -0.02081121038984716\n",
      "HDBSCAN clustering results for recession_fears - num clusters: 6, score: -0.03717756905965803\n",
      "HDBSCAN clustering results for roe_v_wade - num clusters: 6, score: -0.019887985789492788\n",
      "HDBSCAN clustering results for ukraine_war - num clusters: 13, score: -0.02495503297768776\n",
      "HDBSCAN clustering results for vaccine_hesitancy - num clusters: 4, score: -0.015456129509601893\n"
     ]
    }
   ],
   "source": [
    "def cluster_and_compute_silhouette_score(g, nodes):\n",
    "    labels = parse_data.cluster_nodes_hdbscan(g, nodes) \n",
    "    score = parse_data.evaluate_clustering(g, nodes, labels)\n",
    "    return labels, score\n",
    "\n",
    "def cluster_and_compute_silhouette_score_weight(g, nodes):\n",
    "    labels = parse_data.cluster_nodes_hdbscan_weight(g, nodes) \n",
    "    score = parse_data.evaluate_clustering(g, nodes, labels)\n",
    "    return labels, score\n",
    "\n",
    "def cluster_and_evaluate_issues(network_dir, network_names, network_suffix, num_nodes=None):\n",
    "    for name in network_names:\n",
    "        filepath = network_dir + name + network_suffix\n",
    "        g = msg_passing.load_graph_graphml(filepath + \".graphml\") \n",
    "        pg, _ = msg_passing.prune_graph(g)\n",
    "        \n",
    "        # manually change\n",
    "        if(not num_nodes):\n",
    "            total_nodes = len(pg.nodes())\n",
    "            num_nodes = total_nodes\n",
    "        nodes = utils.get_top_n_nodes(pg, num_nodes)\n",
    "        labels, score = cluster_and_compute_silhouette_score(pg, nodes) \n",
    "\n",
    "        num_clusters = len(set(labels))\n",
    "        print(f\"Results for {name}: total nodes: {total_nodes}, num clusters: {num_clusters}, score: {score}\")\n",
    "\n",
    "def cluster_and_evaluate_issues_louvain(network_dir, network_names, network_suffix):\n",
    "    for name in network_names:\n",
    "        filepath = network_dir + name + network_suffix\n",
    "        g = msg_passing.load_graph_graphml(filepath + \".graphml\") \n",
    "        pg, _ = msg_passing.prune_graph(g)\n",
    "\n",
    "        # manually change\n",
    "        total_nodes = len(pg.nodes())\n",
    "        num_nodes = total_nodes\n",
    "        nodes = utils.get_top_n_nodes(pg, num_nodes)\n",
    "\n",
    "        ng = parse_data.reweight_edges_for_louvain(pg, nodes)\n",
    "        louvain_partition = community.best_partition(ng, weight='weight')\n",
    "        node_labels = [louvain_partition[n] for n in nodes]\n",
    "        \n",
    "        baselines.evaluate_cluster_louvain(pg, nodes, baselines.cluster_louvain(pg, nodes))\n",
    "        score = parse_data.evaluate_clustering(pg, nodes, node_labels)\n",
    "\n",
    "        num_clusters = len(set(node_labels))\n",
    "        print(f\"Results for {name}: total nodes: {total_nodes}, num clusters: {num_clusters}, score: {score}\")\n",
    "\n",
    "\n",
    "def cluster_and_evaluate_issues_hdbscan(network_dir, network_names, network_suffix):\n",
    "    for name in network_names:\n",
    "        filepath = network_dir + name + network_suffix\n",
    "        g = msg_passing.load_graph_graphml(filepath + \".graphml\") \n",
    "        pg, _ = msg_passing.prune_graph(g)\n",
    "                \n",
    "        # manually change\n",
    "        total_nodes = len(pg.nodes())\n",
    "        num_nodes = total_nodes\n",
    "        nodes = utils.get_top_n_nodes(pg, num_nodes)\n",
    "        labels, score = cluster_and_compute_silhouette_score(pg, nodes) \n",
    "\n",
    "        num_clusters = len(set(labels))\n",
    "        print(f\"Results for {name}: total nodes: {total_nodes}, num clusters: {num_clusters}, score: {score}\")\n",
    "\n",
    "infiles = [\n",
    "    \"gun_regulations\",\n",
    "    \"immigration\",\n",
    "    \"recession_fears\",\n",
    "    \"roe_v_wade\",\n",
    "    \"ukraine_war\",\n",
    "    \"vaccine_hesitancy\",\n",
    "]\n",
    "outdir = \"output/with_windows/\"\n",
    "#outdir = \"output/random_permutation/\"\n",
    "#outdir = \"output/random_edges/\"\n",
    "#outdir = \"output/random_weights/\"\n",
    "#outdir = \"output/degree_penalty_correctly_weighted/\"\n",
    "out_suffix = \"_network_random_walks_lr_10-3_20K_dc_095_pl_10_bs_10\"\n",
    "#out_suffix = \"_network_random_permutation_baseline_random_walks_lr_10-3_20K_dc_095_pl_10_bs_10\"\n",
    "#out_suffix = \"_network_random_edge_baseline_random_walks_lr_10-3_20K_dc_095_pl_10_bs_10\"\n",
    "#out_suffix = \"_network_random_weight_baseline_random_walks_lr_10-3_20K_dc_095_pl_10_bs_10\"\n",
    "#out_suffix = \"_network_degree_penalty_correctly_weighted_lr_10-3_20K_dc_095_pl_10_bs_10\"\n",
    "#cluster_and_evaluate_issues(outdir, infiles, out_suffix)\n",
    "#cluster_and_evaluate_issues_hdbscan(outdir, infiles, out_suffix)\n",
    "#cluster_and_evaluate_issues_louvain(outdir, infiles, out_suffix)\n",
    "#baselines.evaluate_multiple_issues_louvain(outdir, infiles, out_suffix, num_nodes=None, prune=True)\n",
    "baselines.evaluate_multiple_issues_hdbscan(outdir, infiles, out_suffix, num_nodes=None, prune=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv39': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b876fb38630d8b7eff3227a637f339eaf3b214f70cea0bf24c7a5b65f81667aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
