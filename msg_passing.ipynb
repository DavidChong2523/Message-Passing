{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import sklearn.cluster \n",
    "import plotly.express as px\n",
    "import community\n",
    "\n",
    "import msg_passing\n",
    "import utils\n",
    "import run\n",
    "import display\n",
    "import parse_data\n",
    "import baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(fdir, f_prefix):\n",
    "    g = msg_passing.load_graph_graphml(fdir + f_prefix + \".graphml\")\n",
    "    hist, diagnostic_hist = msg_passing.load_history(fdir + f_prefix + \".pkl\")\n",
    "    return g, hist, diagnostic_hist\n",
    "\n",
    "def view_history(fdir, f_prefix):\n",
    "    hist, _ = msg_passing.load_history(fdir + f_prefix + \".pkl\") \n",
    "    return hist.keys()\n",
    "\n",
    "def plot_run(fdir, f_prefix, target):\n",
    "    print(\"Plotting run for\", fdir + f_prefix)\n",
    "    g = msg_passing.load_graph_graphml(fdir + f_prefix + \".graphml\")\n",
    "    hist, diagnostic_hist = msg_passing.load_history(fdir + f_prefix + \".pkl\")\n",
    "    display.plot_diagnostic(diagnostic_hist)\n",
    "    display.plot_history(hist, target=target)\n",
    "\n",
    "def summmarize_diagnostic(network_dir, network_names, network_suffix):\n",
    "    hist_files = []\n",
    "    graph_files = []\n",
    "    for n in network_names:\n",
    "        h = network_dir + n + network_suffix + \".pkl\"\n",
    "        g = network_dir + n + network_suffix + \".graphml\"\n",
    "        hist_files.append(h)\n",
    "        graph_files.append(g)\n",
    "\n",
    "    fig = display.plot_diagnostic_multiple_issues(hist_files, graph_files, network_names, show=True)\n",
    "    #fig.write_image(\"convergence_plots.pdf\", height=450, width=986)\n",
    "    return fig \n",
    "\n",
    "def summarize_histogram(network_dir, network_names, network_suffix):\n",
    "    graph_files = [network_dir + n + network_suffix + \".graphml\" for n in network_names]\n",
    "    fig = display.plot_cos_dist_histogram_grid(graph_files, network_names, \"Cos Dist Histogram\", 4, 2)\n",
    "    return fig \n",
    "\n",
    "def summarize_confusion_matrix(network_dir, network_names, network_suffix, top_n_nodes, num_nodes=None, drop_noise=True):\n",
    "    view_dir = \"images/view/\"\n",
    "    for n in network_names:\n",
    "        filepath = network_dir + n + network_suffix + \".graphml\"\n",
    "        g = msg_passing.load_graph_graphml(filepath) \n",
    "        pg, _ = msg_passing.prune_graph(g) \n",
    "\n",
    "        if(not num_nodes):\n",
    "            num_nodes = len(pg.nodes())\n",
    "        nodes = utils.get_top_n_nodes(pg, num_nodes)\n",
    "        fig = display.plot_confusion_matrix_with_random_baseline(pg, nodes, top_n_nodes, drop_noise=True, title=\"distance matrix\")\n",
    "        fig.write_html(view_dir + n + \".html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwrite_dir = \"output/pruned_graphs/\"\\nfor n in infiles:\\n    print(n)\\n    fname = outdir + n + out_suffix + \".graphml\"\\n    #fname = indir + n + in_suffix\\n    #g = msg_passing.load_graph_csv(fname, clean_data=True)\\n    #msg_passing.save_graph(g, write_dir + n + \"_full.graphml\")\\n    g = msg_passing.load_graph_graphml(fname)\\n    g = utils.largest_connected_component(g)\\n    pg, _ = msg_passing.prune_graph(g)\\n    msg_passing.save_graph(pg, write_dir + n + \".graphml\")\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infiles = [\n",
    "    \"global_warming_network\",\n",
    "    \"gun_regulations_network\",\n",
    "    \"immigration_network\",\n",
    "    \"inflation_network\",\n",
    "    \"roe_v_wade_network\",\n",
    "    \"trump_impeachment_network\",\n",
    "    \"ukraine_war_network\",\n",
    "    \"vaccine_hesitancy_network\",\n",
    "    \"combined\"\n",
    "]\n",
    "\n",
    "infiles = [\n",
    "    \"global_warming\",\n",
    "    \"gun_regulations\",\n",
    "    \"immigration\",\n",
    "    \"recession_fears\",\n",
    "    \"roe_v_wade\",\n",
    "    \"ukraine_war\",\n",
    "    \"vaccine_hesitancy\",\n",
    "]\n",
    "\n",
    "network_names = [ \n",
    "    \"global warming\",\n",
    "    \"gun regulations\",\n",
    "    \"immigration\",\n",
    "    \"recession fears\",\n",
    "    \"roe v. wade\",\n",
    "    \"ukraine war\",\n",
    "    \"vaccine hesitancy\",\n",
    "]\n",
    "\n",
    "indir = \"input/Networks/\"\n",
    "\n",
    "#outdir = \"output/Incremental_Datasets_2/\"\n",
    "#outdir = \"output/archive/\"\n",
    "\n",
    "outdir = \"output/Networks_v1/\"\n",
    "#outdir = \"output/random_edges/\"\n",
    "outdir = \"output/with_windows/\"\n",
    "#outdir = \"output/degree_penalty/\"\n",
    "#outdir = \"output/correctly_weighted/\"\n",
    "#outdir = \"output/degree_penalty_correctly_weighted/\"\n",
    "\n",
    "in_suffix = \"_network.csv\"\n",
    "\n",
    "#out_suffix = \"_random_walks_lr_10-3_30K_dc_095_pl_10_bs_10\"\n",
    "#out_suffix = \"_v3_random_walk_batch_10_path_10_50K_lr_3_dim_3\"\n",
    "\n",
    "out_suffix = \"_network_random_walks_lr_10-3_20K_dc_095_pl_{path_length}_bs_10\"\n",
    "#out_suffix = \"_network_random_edge_baseline_random_walks_lr_10-3_20K_dc_095_pl_10_bs_10\" \n",
    "out_suffix = \"_network_random_walks_lr_10-3_20K_dc_095_pl_10_bs_10\"\n",
    "#out_suffix = \"_network_degree_penalty_lr_10-3_20K_dc_095_pl_10_bs_10\"\n",
    "#out_suffix = \"_network_correctly_weighted_lr_10-3_20K_dc_095_pl_10_bs_10\"\n",
    "#out_suffix = \"_network_degree_penalty_correctly_weighted_lr_10-3_20K_dc_095_pl_10_bs_10\"\n",
    "\n",
    "net = infiles[5] \n",
    "g, hist, diagnostic_hist = load_results(outdir, net + out_suffix)\n",
    "\n",
    "\n",
    "#print(hist.keys())\n",
    "#display.plot_history_with_reference(hist, \"anthony fauci\")\n",
    "#display.plot_top_n_cluster_evaluations(g, [20, 50, 100], 2, 10)\n",
    "#print(view_history(outdir, net + out_suffix))\n",
    "#plot_run(outdir, net + out_suffix, \"biden\")\n",
    "#_ = display.plot_edge_weight_histogram(g, log_scale=False)\n",
    "#_ = display.plot_degree_histogram(g, log_scale=True)\n",
    "\n",
    "#fig = display.plot_confusion_matrix(g, utils.get_top_n_nodes(g, 20), 2, title=net)\n",
    "#_ = display.plot_cos_dist_histogram(g, title=net)\n",
    "#fig.write_html(\"images/vaccine_heatmap.html\")\n",
    "\n",
    "\n",
    "\n",
    "#_ = summmarize_diagnostic(outdir, infiles, out_suffix)\n",
    "#_ = summarize_histogram(outdir, infiles, out_suffix)\n",
    "#summarize_confusion_matrix(outdir, infiles, out_suffix, 20, num_nodes=50, drop_noise=True)\n",
    "#_ = display.plot_diagnostic_grid(hist_files, graph_files, infiles, \"Update Magnitude and Loss\", 4, 2)\n",
    "\n",
    "\n",
    "g = msg_passing.load_graph_graphml(outdir + infiles[0] + out_suffix + \".graphml\")\n",
    "ag, _ = msg_passing.prune_graph(utils.largest_connected_component(g))\n",
    "g = msg_passing.permute_edges(g) \n",
    "g = utils.largest_connected_component(g)\n",
    "pg, _ = msg_passing.prune_graph(g)\n",
    "msg_passing.save_graph(pg, \"output/test.graphml\")\n",
    "msg_passing.save_graph(ag, \"output/test2.graphml\")\n",
    "\n",
    "\"\"\"\n",
    "write_dir = \"output/pruned_graphs/\"\n",
    "for n in infiles:\n",
    "    print(n)\n",
    "    fname = outdir + n + out_suffix + \".graphml\"\n",
    "    #fname = indir + n + in_suffix\n",
    "    #g = msg_passing.load_graph_csv(fname, clean_data=True)\n",
    "    #msg_passing.save_graph(g, write_dir + n + \"_full.graphml\")\n",
    "    g = msg_passing.load_graph_graphml(fname)\n",
    "    g = utils.largest_connected_component(g)\n",
    "    pg, _ = msg_passing.prune_graph(g)\n",
    "    msg_passing.save_graph(pg, write_dir + n + \".graphml\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shortest_path_network(g, nodes1, nodes2):\n",
    "    subgraph_nodes = set()\n",
    "    for n1 in nodes1:\n",
    "        for n2 in nodes2:\n",
    "            sps = list(nx.all_shortest_paths(g, n1, n2))\n",
    "            for sp in sps:\n",
    "                for n in sp:\n",
    "                    subgraph_nodes.add(n) \n",
    "    \n",
    "    return g.subgraph(subgraph_nodes)\n",
    "\n",
    "gf = \"output/Networks_v1/gun_regulations_network_random_walks_lr_10-3_20K_dc_095_pl_{path_length}_bs_10.graphml\"\n",
    "#gf = \"output/Networks_v1/roe_v_wade_network_random_walks_lr_10-3_20K_dc_095_pl_{path_length}_bs_10.graphml\"\n",
    "gf = \"output/Networks_v1/recession_fears_network_random_walks_lr_10-3_20K_dc_095_pl_{path_length}_bs_10.graphml\"\n",
    "g = msg_passing.load_graph_graphml(gf)\n",
    "pg, _ = msg_passing.prune_graph(g) \n",
    "n1 = [\"second amendment\", \"bruen\", \"greg abbott\", \"gerald smith\", \"iowa firearms coalition\", \"supreme court\"]\n",
    "#n2 = [\"second amendment foundation\", \"adam kraut\"]\n",
    "n2 = [\"joe biden\", \"kamala harris\", \"a ban on assault weapons\", \"biden\", \"white house\"]\n",
    "#n1 = [\"donald trump\", \"white house\", \"supreme court\", \"clarence thomas\"]\n",
    "#n2 = [\"republican\", \"republicans\", \"gop\", \"arizona\", \"planned parenthood\", \"anti-abortion\"]\n",
    "n1 = [\"opec\", \"fox news\", \"saudis\"]\n",
    "n2 = [\"jerome powell\", \"joe biden\", \"janet yellen\"]\n",
    "\n",
    "sg = get_shortest_path_network(pg, n1, n2)\n",
    "write_dir = \"output/cyto_pruned_networks/\"\n",
    "outname = write_dir + \"recession_1.graphml\" \n",
    "msg_passing.save_graph(sg, outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDBSCAN clustering results for gun_regulations - num clusters: 13, score: -0.040456127676587926\n",
      "HDBSCAN clustering results for immigration - num clusters: 10, score: -0.02081121038984716\n",
      "HDBSCAN clustering results for recession_fears - num clusters: 6, score: -0.03717756905965803\n",
      "HDBSCAN clustering results for roe_v_wade - num clusters: 6, score: -0.019887985789492788\n",
      "HDBSCAN clustering results for ukraine_war - num clusters: 13, score: -0.02495503297768776\n",
      "HDBSCAN clustering results for vaccine_hesitancy - num clusters: 4, score: -0.015456129509601893\n"
     ]
    }
   ],
   "source": [
    "def cluster_and_compute_silhouette_score(g, nodes):\n",
    "    labels = parse_data.cluster_nodes_hdbscan(g, nodes) \n",
    "    score = parse_data.evaluate_clustering(g, nodes, labels)\n",
    "    return labels, score\n",
    "\n",
    "def cluster_and_evaluate_issues(network_dir, network_names, network_suffix, num_nodes=None):\n",
    "    for name in network_names:\n",
    "        filepath = network_dir + name + network_suffix\n",
    "        g = msg_passing.load_graph_graphml(filepath + \".graphml\") \n",
    "        pg, _ = msg_passing.prune_graph(g)\n",
    "        \n",
    "        # manually change\n",
    "        if(not num_nodes):\n",
    "            total_nodes = len(pg.nodes())\n",
    "            num_nodes = total_nodes\n",
    "        nodes = utils.get_top_n_nodes(pg, num_nodes)\n",
    "        labels, score = cluster_and_compute_silhouette_score(pg, nodes) \n",
    "\n",
    "        num_clusters = len(set(labels))\n",
    "        print(f\"Results for {name}: total nodes: {total_nodes}, num clusters: {num_clusters}, score: {score}\")\n",
    "        \n",
    "infiles = [\n",
    "    \"gun_regulations\",\n",
    "    \"immigration\",\n",
    "    \"recession_fears\",\n",
    "    \"roe_v_wade\",\n",
    "    \"ukraine_war\",\n",
    "    \"vaccine_hesitancy\",\n",
    "]\n",
    "outdir = \"output/with_windows/\"\n",
    "#outdir = \"output/random_permutation/\"\n",
    "#outdir = \"output/random_edges/\"\n",
    "#outdir = \"output/random_weights/\"\n",
    "#outdir = \"output/degree_penalty_correctly_weighted/\"\n",
    "out_suffix = \"_network_random_walks_lr_10-3_20K_dc_095_pl_10_bs_10\"\n",
    "#out_suffix = \"_network_random_permutation_baseline_random_walks_lr_10-3_20K_dc_095_pl_10_bs_10\"\n",
    "#out_suffix = \"_network_random_edge_baseline_random_walks_lr_10-3_20K_dc_095_pl_10_bs_10\"\n",
    "#out_suffix = \"_network_random_weight_baseline_random_walks_lr_10-3_20K_dc_095_pl_10_bs_10\"\n",
    "#out_suffix = \"_network_degree_penalty_correctly_weighted_lr_10-3_20K_dc_095_pl_10_bs_10\"\n",
    "#cluster_and_evaluate_issues(outdir, infiles, out_suffix)\n",
    "#cluster_and_evaluate_issues_hdbscan(outdir, infiles, out_suffix)\n",
    "#cluster_and_evaluate_issues_louvain(outdir, infiles, out_suffix)\n",
    "#baselines.evaluate_multiple_issues_louvain(outdir, infiles, out_suffix, num_nodes=None, prune=True)\n",
    "baselines.evaluate_multiple_issues_hdbscan(outdir, infiles, out_suffix, num_nodes=None, prune=True)\n",
    "\n",
    "# TODO: plot degree distribution of permuted graphs\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv39': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b876fb38630d8b7eff3227a637f339eaf3b214f70cea0bf24c7a5b65f81667aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
